{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis demonstration\n",
    "\n",
    "This notebook contains an example of how to account for uncertainty in the parameters of the production process. The resulting variability is explored through a Monte Carlo-based sensitivity analysis, in which different values are used to run the facility and the outputs of interest are compiled.\n",
    "\n",
    "First we set up the Facility to analyse, just as in previous demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biopharma as bp\n",
    "\n",
    "facility = bp.Facility(data_path='data')\n",
    "\n",
    "# Define the steps needed to create our single product\n",
    "from biopharma.process_steps import (\n",
    "    \n",
    ")\n",
    "steps = [\n",
    "    \n",
    "]\n",
    "product = bp.Product(facility, steps)\n",
    "\n",
    "# Need to explicitly call this so that later functions can refer to quantities of interest \n",
    "facility.load_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the facility is created, we can set up the sensitivity analysis. This requires two pieces of information:\n",
    "* the aspects to be varied, and\n",
    "* the outputs we are interested in.\n",
    "\n",
    "The outputs are declared through selector functions, similar to how [optimisation targets are specified](Optimisation_demo.ipynb#optimisation_targets). In this example, we choose to track four outputs. Note that these outputs do not need to be related to the product: any parameter or output of a component can be tracked, by providing an appropriate selector function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biopharma import optimisation as opt\n",
    "\n",
    "analyser = opt.SensitivityAnalyser(facility)\n",
    "\n",
    "# Specify the variables whose sensitivity we are interested in.\n",
    "analyser.add_output(\"CoG\", component=opt.sel.product(0), item=\"cogs\")\n",
    "analyser.add_output(\"step_int_param\", component=opt.sel.step('test_step'), item=\"int_param\")\n",
    "analyser.add_output(\"facility_info\", component=opt.sel.facility(), item=\"param\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable (uncertain aspect), we must say what distribution represents its possible values. There are several families of distributions available, each governed by appropriate parameters:\n",
    "\n",
    "* Uniform (over a given domain)\n",
    "* Triangular (over a given domain)\n",
    "* Gaussian (with a given mean and variance)\n",
    "\n",
    "Here, we choose two variables. Both are given uniform distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which aspects to vary.\n",
    "\n",
    "param1_mean = facility.products[0].parameters[\"param1\"]\n",
    "param1_width = 2 * param1_mean.units\n",
    "analyser.add_variable(gen=opt.dist.Uniform(param1_mean - param1_width, param1_mean + param1_width),\n",
    "                      component=opt.sel.product(), item=\"param\")\n",
    "\n",
    "param2_mean = facility.products[0].parameters[\"param2\"]\n",
    "param2_width = 100000 * param2_mean.units\n",
    "analyser.add_variable(gen=opt.dist.Uniform(param2_mean - param2_width, param2_mean + param2_width),\n",
    "                      component=opt.sel.product(), item=\"param2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run the sensitivity analysis and collect the results.\n",
    "\n",
    "The commented-out line (starting with a '# ') shows how to override the number of samples, which by default is set to 100 in the [SensitivityAnalyser.yaml](data/SensitivityAnalyser.yaml) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyser.parameters[\"numberOfSamples\"] = 1000\n",
    "analyser.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each output, we can access the minimum and maximum values recorded (```min```, ```max```), the average value (```avg```) and the variance (```var```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Minimum CoG: {:f}\".format(analyser.outputs[\"CoG\"][\"min\"]))\n",
    "print(\"Maximum CoG: {:f}\".format(analyser.outputs[\"CoG\"][\"max\"]))\n",
    "from numpy import sqrt\n",
    "print(\"Average CoG: {:f} +/- {:f}\".format(analyser.outputs[\"CoG\"][\"avg\"], sqrt(analyser.outputs[\"CoG\"][\"var\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly access the list of all the values encountered (```all```), to examine their distribution in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of the CoG\n",
    "import matplotlib.pyplot as plt\n",
    "# The values to be plotted must first have their units removed\n",
    "values = [value.magnitude for value in analyser.outputs[\"CoG\"][\"all\"]]\n",
    "units = analyser.outputs[\"CoG\"][\"all\"][0].units\n",
    "plt.hist(values)\n",
    "plt.xlabel(\"Cost of goods ({})\".format(units))\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameter values can lead to errors when evaluating the facility output (e.g. if a negative value is chosen for a quantity which must be positive). A careful choice of distributions for the variables can help avoid such problems. If, however, an error does occur, that particular run will be discarded and will not count towards the total number of runs requested. The number of failed runs is available as an output after the analysis is complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.outputs[\"failed_runs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with optimisation, it is possible to replicate a sensitivity analysis by specifying an initial random state. For more details, see the [relevant section in the optimisation demo](Optimisation_demo.ipynb#replication)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
